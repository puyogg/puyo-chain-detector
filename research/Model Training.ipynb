{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PUYO_W = 16\n",
    "PUYO_H = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = joblib.load('dataset-images.joblib')\n",
    "all_y = joblib.load('dataset-labels.joblib')\n",
    "\n",
    "# Normalize values between [-1, 1]\n",
    "all_x = ((all_x / 255) - 0.5) / 0.5\n",
    "\n",
    "# Put the dims in NCHW order as PyTorch expects it to be\n",
    "all_x = all_x.transpose((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split into training and validation sets\n",
    "N = all_x.shape[0]\n",
    "inds = np.arange(N)\n",
    "np.random.shuffle(inds)\n",
    "\n",
    "x_train = all_x[inds[:(math.floor(0.75 * N))], ...]\n",
    "y_train = all_y[inds[:(math.floor(0.75 * N))], ...]\n",
    "x_test = all_x[inds[(math.floor(0.75 * N)):], ...]\n",
    "y_test = all_y[inds[(math.floor(0.75 * N)):], ...]\n",
    "x_train = torch.tensor(x_train, dtype=torch.float, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Dataset and DataLoader\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=400),\n",
    "    'val': DataLoader(test_ds, batch_size=800)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    'train': x_train.shape[0],\n",
    "    'val': x_test.shape[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0', 'J', 'R', 'G', 'B', 'Y', 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuyoClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(720, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 7),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3 * PUYO_H * PUYO_W)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "# lr = 0.0005\n",
    "model = PuyoClassifier()\n",
    "model.cuda(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Track loss and accuracy over epochs\n",
    "    hist = pd.DataFrame(columns=['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        hist_row = [epoch]\n",
    "        end_early = False\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Set model to training mode\n",
    "            else:\n",
    "                model.eval() # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # # Run on CUDA\n",
    "                # inputs = inputs.to(device)\n",
    "                # labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + Optimize only if in training\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Stats\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # if phase == 'train':\n",
    "            #     scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if (epoch_acc < 0.01):\n",
    "                print('Preds', preds, preds.dtype)\n",
    "                print('Labels', labels.data, labels.data.dtype)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            hist_row.append(epoch_loss)\n",
    "            hist_row.append(epoch_acc.item())\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                if epoch_acc > 0.994:\n",
    "                    end_early = True\n",
    "\n",
    "        hist.loc[epoch] = hist_row\n",
    "        print()\n",
    "        if end_early:\n",
    "            break\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/999\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9912\n",
      "val Loss: 0.0014 Acc: 0.9997\n",
      "\n",
      "Training complete in 0m 38s\n",
      "Best val Acc: 0.999689\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = train_model(model, criterion, optimizer, exp_lr_scheduler, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), \"puyo-classifier-feb8-2021.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "trained_model.train(False)\n",
    "dummy = torch.randn(200, 3, 15, 16, device=device)\n",
    "torch_out = trained_model(dummy)\n",
    "torch.onnx.export(trained_model, dummy, \"puyo-mlp-gpu.onnx\", export_params=True, opset_version=10, do_constant_folding=True, input_names=[\"input\"], output_names=[\"output\"], dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "cpu_model = trained_model.to('cpu')\n",
    "cpu_model.train(False)\n",
    "dummy = torch.randn(200, 3, 15, 16)\n",
    "torch_out = cpu_model(dummy)\n",
    "torch.onnx.export(cpu_model, dummy, \"puyo-mlp-cpu.onnx\", export_params=True, opset_version=10, do_constant_folding=True, input_names=[\"input\"], output_names=[\"output\"], dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}})"
   ]
  }
 ]
}